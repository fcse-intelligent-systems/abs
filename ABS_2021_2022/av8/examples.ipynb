{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ABS_av8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-rl2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngnU__JflPUM",
        "outputId": "6b2f6d0b-9adc-4cf1-edd8-f70656dcadba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-rl2\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▎                         | 10 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 20 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 30 kB 37.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 40 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 51 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 730 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.44.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (14.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (4.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.0.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.25.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-rl2) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7cG91_FQlHXw"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import EpsGreedyQPolicy, BoltzmannQPolicy\n",
        "from rl.agents.dqn import DQNAgent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v0')"
      ],
      "metadata": {
        "id": "6C8zhqoYnuj1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_actions = env.action_space.n\n",
        "state_space_shape = env.observation_space.shape\n",
        "print(num_actions)\n",
        "print(state_space_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCYuuJhknzEB",
        "outputId": "18f6b96c-7a28-40e4-da30-5805c5c2c4d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "(4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(1,) + state_space_shape))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_actions, activation='linear'))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbiKivnSn9Ud",
        "outputId": "107cf113-34d2-496f-a3c8-ced4b5c6c6b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 4)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 24)                120       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 24)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 24)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 770\n",
            "Trainable params: 770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = SequentialMemory(limit=50000, window_length=1)"
      ],
      "metadata": {
        "id": "nYLJ394loZrR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy = EpsGreedyQPolicy(eps=0.1)"
      ],
      "metadata": {
        "id": "Zax2f1UMohOd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = DQNAgent(model=model, nb_actions=num_actions, memory=memory,\n",
        "                 nb_steps_warmup=1000, target_model_update=1, policy=policy)"
      ],
      "metadata": {
        "id": "TMuE8YSeorSv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.compile(Adam(lr=1e-3), metrics=['mae'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rYha4svpUER",
        "outputId": "cef57540-e84e-4bdd-c618-485c23ffaa03"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.fit(env, nb_steps=2000, visualize=False, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hyr0mfUps0f",
        "outputId": "cefa40e9-b00d-4679-fe1d-257ccbdecc8c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 2000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    9/2000: episode: 1, duration: 1.972s, episode steps:   9, steps per second:   5, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "   19/2000: episode: 2, duration: 0.040s, episode steps:  10, steps per second: 253, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "   36/2000: episode: 3, duration: 0.060s, episode steps:  17, steps per second: 281, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.706 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "   45/2000: episode: 4, duration: 0.037s, episode steps:   9, steps per second: 241, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "   54/2000: episode: 5, duration: 0.034s, episode steps:   9, steps per second: 261, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "   78/2000: episode: 6, duration: 0.089s, episode steps:  24, steps per second: 269, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.708 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "   89/2000: episode: 7, duration: 0.042s, episode steps:  11, steps per second: 265, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "   98/2000: episode: 8, duration: 0.034s, episode steps:   9, steps per second: 264, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  117/2000: episode: 9, duration: 0.066s, episode steps:  19, steps per second: 286, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.789 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  130/2000: episode: 10, duration: 0.049s, episode steps:  13, steps per second: 264, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  138/2000: episode: 11, duration: 0.036s, episode steps:   8, steps per second: 224, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  156/2000: episode: 12, duration: 0.066s, episode steps:  18, steps per second: 273, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  172/2000: episode: 13, duration: 0.062s, episode steps:  16, steps per second: 258, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.688 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  190/2000: episode: 14, duration: 0.065s, episode steps:  18, steps per second: 276, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  199/2000: episode: 15, duration: 0.039s, episode steps:   9, steps per second: 230, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  226/2000: episode: 16, duration: 0.104s, episode steps:  27, steps per second: 260, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  238/2000: episode: 17, duration: 0.045s, episode steps:  12, steps per second: 264, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  250/2000: episode: 18, duration: 0.044s, episode steps:  12, steps per second: 271, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  259/2000: episode: 19, duration: 0.039s, episode steps:   9, steps per second: 231, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  278/2000: episode: 20, duration: 0.069s, episode steps:  19, steps per second: 275, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.737 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  298/2000: episode: 21, duration: 0.076s, episode steps:  20, steps per second: 263, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  316/2000: episode: 22, duration: 0.071s, episode steps:  18, steps per second: 253, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  329/2000: episode: 23, duration: 0.047s, episode steps:  13, steps per second: 277, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.846 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  340/2000: episode: 24, duration: 0.041s, episode steps:  11, steps per second: 267, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  350/2000: episode: 25, duration: 0.038s, episode steps:  10, steps per second: 262, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  364/2000: episode: 26, duration: 0.051s, episode steps:  14, steps per second: 273, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.786 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  376/2000: episode: 27, duration: 0.048s, episode steps:  12, steps per second: 250, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  398/2000: episode: 28, duration: 0.080s, episode steps:  22, steps per second: 277, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.773 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  411/2000: episode: 29, duration: 0.048s, episode steps:  13, steps per second: 269, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.846 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  421/2000: episode: 30, duration: 0.039s, episode steps:  10, steps per second: 256, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  431/2000: episode: 31, duration: 0.044s, episode steps:  10, steps per second: 229, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  445/2000: episode: 32, duration: 0.065s, episode steps:  14, steps per second: 217, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.786 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  462/2000: episode: 33, duration: 0.071s, episode steps:  17, steps per second: 239, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  476/2000: episode: 34, duration: 0.081s, episode steps:  14, steps per second: 173, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.857 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  485/2000: episode: 35, duration: 0.038s, episode steps:   9, steps per second: 238, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  496/2000: episode: 36, duration: 0.045s, episode steps:  11, steps per second: 244, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  506/2000: episode: 37, duration: 0.038s, episode steps:  10, steps per second: 264, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  518/2000: episode: 38, duration: 0.045s, episode steps:  12, steps per second: 267, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  531/2000: episode: 39, duration: 0.053s, episode steps:  13, steps per second: 247, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.846 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  541/2000: episode: 40, duration: 0.038s, episode steps:  10, steps per second: 265, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  551/2000: episode: 41, duration: 0.044s, episode steps:  10, steps per second: 227, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  566/2000: episode: 42, duration: 0.054s, episode steps:  15, steps per second: 279, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  590/2000: episode: 43, duration: 0.087s, episode steps:  24, steps per second: 275, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  616/2000: episode: 44, duration: 0.095s, episode steps:  26, steps per second: 273, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  625/2000: episode: 45, duration: 0.035s, episode steps:   9, steps per second: 259, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  637/2000: episode: 46, duration: 0.048s, episode steps:  12, steps per second: 252, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  650/2000: episode: 47, duration: 0.054s, episode steps:  13, steps per second: 239, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.846 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  665/2000: episode: 48, duration: 0.063s, episode steps:  15, steps per second: 240, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  680/2000: episode: 49, duration: 0.057s, episode steps:  15, steps per second: 264, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  689/2000: episode: 50, duration: 0.036s, episode steps:   9, steps per second: 253, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  702/2000: episode: 51, duration: 0.054s, episode steps:  13, steps per second: 243, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.846 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  713/2000: episode: 52, duration: 0.042s, episode steps:  11, steps per second: 262, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  722/2000: episode: 53, duration: 0.047s, episode steps:   9, steps per second: 190, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  731/2000: episode: 54, duration: 0.035s, episode steps:   9, steps per second: 254, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  747/2000: episode: 55, duration: 0.061s, episode steps:  16, steps per second: 263, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  762/2000: episode: 56, duration: 0.063s, episode steps:  15, steps per second: 237, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  777/2000: episode: 57, duration: 0.053s, episode steps:  15, steps per second: 281, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  788/2000: episode: 58, duration: 0.040s, episode steps:  11, steps per second: 276, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  805/2000: episode: 59, duration: 0.070s, episode steps:  17, steps per second: 244, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  815/2000: episode: 60, duration: 0.046s, episode steps:  10, steps per second: 218, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  825/2000: episode: 61, duration: 0.040s, episode steps:  10, steps per second: 249, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  838/2000: episode: 62, duration: 0.052s, episode steps:  13, steps per second: 249, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.846 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  853/2000: episode: 63, duration: 0.059s, episode steps:  15, steps per second: 256, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  865/2000: episode: 64, duration: 0.048s, episode steps:  12, steps per second: 249, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  875/2000: episode: 65, duration: 0.049s, episode steps:  10, steps per second: 204, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  901/2000: episode: 66, duration: 0.100s, episode steps:  26, steps per second: 259, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  913/2000: episode: 67, duration: 0.047s, episode steps:  12, steps per second: 254, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  922/2000: episode: 68, duration: 0.040s, episode steps:   9, steps per second: 226, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  933/2000: episode: 69, duration: 0.042s, episode steps:  11, steps per second: 262, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  942/2000: episode: 70, duration: 0.034s, episode steps:   9, steps per second: 264, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  956/2000: episode: 71, duration: 0.052s, episode steps:  14, steps per second: 272, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.857 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  972/2000: episode: 72, duration: 0.068s, episode steps:  16, steps per second: 235, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n",
            "  992/2000: episode: 73, duration: 0.074s, episode steps:  20, steps per second: 272, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: --, mae: --, mean_q: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1008/2000: episode: 74, duration: 1.475s, episode steps:  16, steps per second:  11, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.812 [0.000, 1.000],  loss: 0.647233, mae: 0.690568, mean_q: -0.009927\n",
            " 1017/2000: episode: 75, duration: 0.133s, episode steps:   9, steps per second:  68, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 0.649041, mae: 0.660786, mean_q: 0.069060\n",
            " 1027/2000: episode: 76, duration: 0.133s, episode steps:  10, steps per second:  75, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 0.643765, mae: 0.654605, mean_q: 0.171786\n",
            " 1039/2000: episode: 77, duration: 0.171s, episode steps:  12, steps per second:  70, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: 0.643834, mae: 0.660407, mean_q: 0.328332\n",
            " 1048/2000: episode: 78, duration: 0.137s, episode steps:   9, steps per second:  65, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 0.646171, mae: 0.661554, mean_q: 0.448432\n",
            " 1057/2000: episode: 79, duration: 0.125s, episode steps:   9, steps per second:  72, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 0.741696, mae: 0.711241, mean_q: 0.616559\n",
            " 1069/2000: episode: 80, duration: 0.154s, episode steps:  12, steps per second:  78, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: 0.787233, mae: 0.737793, mean_q: 0.743561\n",
            " 1078/2000: episode: 81, duration: 0.116s, episode steps:   9, steps per second:  78, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 0.821380, mae: 0.781840, mean_q: 0.898034\n",
            " 1089/2000: episode: 82, duration: 0.146s, episode steps:  11, steps per second:  75, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 0.861889, mae: 0.829983, mean_q: 1.144239\n",
            " 1098/2000: episode: 83, duration: 0.124s, episode steps:   9, steps per second:  72, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 0.912995, mae: 0.906764, mean_q: 1.345869\n",
            " 1107/2000: episode: 84, duration: 0.126s, episode steps:   9, steps per second:  71, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 1.266908, mae: 1.076230, mean_q: 1.514025\n",
            " 1117/2000: episode: 85, duration: 0.150s, episode steps:  10, steps per second:  67, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 1.262692, mae: 1.149665, mean_q: 1.821956\n",
            " 1127/2000: episode: 86, duration: 0.133s, episode steps:  10, steps per second:  75, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 1.354914, mae: 1.296340, mean_q: 2.199364\n",
            " 1137/2000: episode: 87, duration: 0.130s, episode steps:  10, steps per second:  77, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 1.561544, mae: 1.463113, mean_q: 2.432768\n",
            " 1147/2000: episode: 88, duration: 0.153s, episode steps:  10, steps per second:  65, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 2.066401, mae: 1.772790, mean_q: 2.786815\n",
            " 1157/2000: episode: 89, duration: 0.135s, episode steps:  10, steps per second:  74, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 2.105625, mae: 1.892315, mean_q: 2.911392\n",
            " 1166/2000: episode: 90, duration: 0.129s, episode steps:   9, steps per second:  70, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 1.700110, mae: 1.918663, mean_q: 3.148406\n",
            " 1177/2000: episode: 91, duration: 0.138s, episode steps:  11, steps per second:  80, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 2.146859, mae: 2.231540, mean_q: 3.562602\n",
            " 1187/2000: episode: 92, duration: 0.126s, episode steps:  10, steps per second:  79, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 2.306076, mae: 2.392363, mean_q: 3.735503\n",
            " 1198/2000: episode: 93, duration: 0.141s, episode steps:  11, steps per second:  78, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.091 [0.000, 1.000],  loss: 2.435153, mae: 2.620999, mean_q: 4.082072\n",
            " 1209/2000: episode: 94, duration: 0.142s, episode steps:  11, steps per second:  77, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 2.461882, mae: 2.806537, mean_q: 4.278903\n",
            " 1219/2000: episode: 95, duration: 0.124s, episode steps:  10, steps per second:  81, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 2.508273, mae: 3.114906, mean_q: 5.036002\n",
            " 1230/2000: episode: 96, duration: 0.144s, episode steps:  11, steps per second:  76, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 3.738156, mae: 3.349903, mean_q: 5.213084\n",
            " 1240/2000: episode: 97, duration: 0.135s, episode steps:  10, steps per second:  74, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 2.558854, mae: 3.353857, mean_q: 5.244157\n",
            " 1250/2000: episode: 98, duration: 0.149s, episode steps:  10, steps per second:  67, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 3.570977, mae: 3.614767, mean_q: 5.609436\n",
            " 1259/2000: episode: 99, duration: 0.136s, episode steps:   9, steps per second:  66, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 3.690241, mae: 3.722962, mean_q: 5.835261\n",
            " 1269/2000: episode: 100, duration: 0.158s, episode steps:  10, steps per second:  63, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 4.129046, mae: 3.992307, mean_q: 6.323732\n",
            " 1279/2000: episode: 101, duration: 0.133s, episode steps:  10, steps per second:  75, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 4.940481, mae: 4.067862, mean_q: 6.289847\n",
            " 1289/2000: episode: 102, duration: 0.133s, episode steps:  10, steps per second:  75, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 3.647985, mae: 3.911041, mean_q: 6.115035\n",
            " 1298/2000: episode: 103, duration: 0.111s, episode steps:   9, steps per second:  81, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 3.204001, mae: 3.819934, mean_q: 6.054949\n",
            " 1309/2000: episode: 104, duration: 0.145s, episode steps:  11, steps per second:  76, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 2.648475, mae: 3.708074, mean_q: 6.005764\n",
            " 1322/2000: episode: 105, duration: 0.179s, episode steps:  13, steps per second:  73, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 2.712626, mae: 3.701114, mean_q: 5.983507\n",
            " 1338/2000: episode: 106, duration: 0.193s, episode steps:  16, steps per second:  83, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 2.642181, mae: 3.571639, mean_q: 5.704877\n",
            " 1358/2000: episode: 107, duration: 0.248s, episode steps:  20, steps per second:  80, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 2.763561, mae: 3.656921, mean_q: 5.804550\n",
            " 1372/2000: episode: 108, duration: 0.170s, episode steps:  14, steps per second:  82, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.357 [0.000, 1.000],  loss: 2.784140, mae: 3.704065, mean_q: 5.882081\n",
            " 1382/2000: episode: 109, duration: 0.131s, episode steps:  10, steps per second:  76, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 2.401422, mae: 3.624786, mean_q: 5.847173\n",
            " 1391/2000: episode: 110, duration: 0.116s, episode steps:   9, steps per second:  77, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.111 [0.000, 1.000],  loss: 2.652387, mae: 3.718281, mean_q: 5.990599\n",
            " 1400/2000: episode: 111, duration: 0.115s, episode steps:   9, steps per second:  78, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 2.556423, mae: 3.795686, mean_q: 6.155832\n",
            " 1417/2000: episode: 112, duration: 0.225s, episode steps:  17, steps per second:  75, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 2.457657, mae: 3.690468, mean_q: 5.917981\n",
            " 1435/2000: episode: 113, duration: 0.225s, episode steps:  18, steps per second:  80, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 3.245023, mae: 3.858107, mean_q: 6.061769\n",
            " 1446/2000: episode: 114, duration: 0.139s, episode steps:  11, steps per second:  79, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 2.328864, mae: 3.806389, mean_q: 6.184107\n",
            " 1467/2000: episode: 115, duration: 0.260s, episode steps:  21, steps per second:  81, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 2.814560, mae: 3.945235, mean_q: 6.372858\n",
            " 1480/2000: episode: 116, duration: 0.154s, episode steps:  13, steps per second:  84, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 3.069442, mae: 4.015722, mean_q: 6.317685\n",
            " 1496/2000: episode: 117, duration: 0.203s, episode steps:  16, steps per second:  79, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.920090, mae: 4.120234, mean_q: 6.562187\n",
            " 1517/2000: episode: 118, duration: 0.270s, episode steps:  21, steps per second:  78, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 2.876043, mae: 4.192241, mean_q: 6.808394\n",
            " 1530/2000: episode: 119, duration: 0.174s, episode steps:  13, steps per second:  75, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 3.080792, mae: 4.391430, mean_q: 7.115502\n",
            " 1539/2000: episode: 120, duration: 0.119s, episode steps:   9, steps per second:  76, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 3.183640, mae: 4.572735, mean_q: 7.473193\n",
            " 1550/2000: episode: 121, duration: 0.143s, episode steps:  11, steps per second:  77, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 3.572874, mae: 4.698777, mean_q: 7.592610\n",
            " 1559/2000: episode: 122, duration: 0.135s, episode steps:   9, steps per second:  67, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 4.105460, mae: 4.823688, mean_q: 7.799689\n",
            " 1571/2000: episode: 123, duration: 0.168s, episode steps:  12, steps per second:  71, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 3.832556, mae: 4.721945, mean_q: 7.608551\n",
            " 1580/2000: episode: 124, duration: 0.139s, episode steps:   9, steps per second:  65, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 3.259676, mae: 4.570696, mean_q: 7.356486\n",
            " 1593/2000: episode: 125, duration: 0.172s, episode steps:  13, steps per second:  75, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 3.766842, mae: 4.743244, mean_q: 7.648394\n",
            " 1605/2000: episode: 126, duration: 0.166s, episode steps:  12, steps per second:  72, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 3.086623, mae: 4.764146, mean_q: 7.819960\n",
            " 1615/2000: episode: 127, duration: 0.129s, episode steps:  10, steps per second:  77, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.300 [0.000, 1.000],  loss: 3.569520, mae: 4.819782, mean_q: 7.886822\n",
            " 1631/2000: episode: 128, duration: 0.207s, episode steps:  16, steps per second:  77, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 4.007005, mae: 4.914798, mean_q: 7.973661\n",
            " 1666/2000: episode: 129, duration: 0.454s, episode steps:  35, steps per second:  77, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 4.080247, mae: 4.958510, mean_q: 8.111642\n",
            " 1684/2000: episode: 130, duration: 0.252s, episode steps:  18, steps per second:  72, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.474526, mae: 4.926226, mean_q: 8.118683\n",
            " 1709/2000: episode: 131, duration: 0.330s, episode steps:  25, steps per second:  76, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 3.846142, mae: 4.922385, mean_q: 8.032368\n",
            " 1735/2000: episode: 132, duration: 0.337s, episode steps:  26, steps per second:  77, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.423 [0.000, 1.000],  loss: 3.441691, mae: 4.920491, mean_q: 8.148843\n",
            " 1750/2000: episode: 133, duration: 0.191s, episode steps:  15, steps per second:  79, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 3.745728, mae: 5.060176, mean_q: 8.266307\n",
            " 1762/2000: episode: 134, duration: 0.161s, episode steps:  12, steps per second:  75, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 3.006520, mae: 4.997077, mean_q: 8.398860\n",
            " 1773/2000: episode: 135, duration: 0.143s, episode steps:  11, steps per second:  77, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 4.070309, mae: 5.251961, mean_q: 8.674575\n",
            " 1783/2000: episode: 136, duration: 0.138s, episode steps:  10, steps per second:  72, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 4.278385, mae: 5.488967, mean_q: 9.038672\n",
            " 1794/2000: episode: 137, duration: 0.160s, episode steps:  11, steps per second:  69, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.273 [0.000, 1.000],  loss: 5.331434, mae: 5.734002, mean_q: 9.352936\n",
            " 1806/2000: episode: 138, duration: 0.173s, episode steps:  12, steps per second:  69, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 4.629757, mae: 5.510161, mean_q: 9.056823\n",
            " 1843/2000: episode: 139, duration: 0.450s, episode steps:  37, steps per second:  82, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 4.368421, mae: 5.385049, mean_q: 8.876026\n",
            " 1854/2000: episode: 140, duration: 0.151s, episode steps:  11, steps per second:  73, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 3.586938, mae: 5.272373, mean_q: 8.838444\n",
            " 1864/2000: episode: 141, duration: 0.145s, episode steps:  10, steps per second:  69, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.300 [0.000, 1.000],  loss: 4.433958, mae: 5.479740, mean_q: 9.075678\n",
            " 1877/2000: episode: 142, duration: 0.167s, episode steps:  13, steps per second:  78, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 4.475397, mae: 5.412282, mean_q: 8.925735\n",
            " 1885/2000: episode: 143, duration: 0.121s, episode steps:   8, steps per second:  66, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.125 [0.000, 1.000],  loss: 4.151562, mae: 5.325659, mean_q: 8.748964\n",
            " 1896/2000: episode: 144, duration: 0.149s, episode steps:  11, steps per second:  74, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 3.939725, mae: 5.328976, mean_q: 8.763337\n",
            " 1904/2000: episode: 145, duration: 0.110s, episode steps:   8, steps per second:  73, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.125 [0.000, 1.000],  loss: 3.164766, mae: 5.101857, mean_q: 8.571200\n",
            " 1915/2000: episode: 146, duration: 0.142s, episode steps:  11, steps per second:  77, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 3.378235, mae: 5.368219, mean_q: 8.981864\n",
            " 1924/2000: episode: 147, duration: 0.116s, episode steps:   9, steps per second:  78, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 4.812944, mae: 5.463737, mean_q: 8.961329\n",
            " 1936/2000: episode: 148, duration: 0.148s, episode steps:  12, steps per second:  81, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 4.768683, mae: 5.436156, mean_q: 8.887074\n",
            " 1953/2000: episode: 149, duration: 0.215s, episode steps:  17, steps per second:  79, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.412 [0.000, 1.000],  loss: 4.055095, mae: 5.269593, mean_q: 8.692524\n",
            " 1966/2000: episode: 150, duration: 0.171s, episode steps:  13, steps per second:  76, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 4.005707, mae: 5.302132, mean_q: 8.813239\n",
            " 1979/2000: episode: 151, duration: 0.162s, episode steps:  13, steps per second:  80, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 3.606312, mae: 5.205005, mean_q: 8.631109\n",
            "done, took 20.527 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd3de39e090>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.test(env, nb_episodes=10, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6FVaElAqQZl",
        "outputId": "3ed2c8b8-e7a5-4309-d3fa-1b0ea853e651"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 12.000, steps: 12\n",
            "Episode 2: reward: 13.000, steps: 13\n",
            "Episode 3: reward: 14.000, steps: 14\n",
            "Episode 4: reward: 12.000, steps: 12\n",
            "Episode 5: reward: 15.000, steps: 15\n",
            "Episode 6: reward: 11.000, steps: 11\n",
            "Episode 7: reward: 16.000, steps: 16\n",
            "Episode 8: reward: 15.000, steps: 15\n",
            "Episode 9: reward: 16.000, steps: 16\n",
            "Episode 10: reward: 17.000, steps: 17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd3de098310>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v0')\n",
        "\n",
        "num_actions = env.action_space.n\n",
        "state_space_shape = env.observation_space.shape\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(1,) + state_space_shape))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Dense(num_actions, activation='linear'))\n",
        "\n",
        "memory = SequentialMemory(limit=50000, window_length=1)\n",
        "policy = BoltzmannQPolicy()  # EpsGreedyQPolicy(eps=0.1)\n",
        "agent = DQNAgent(model=model, nb_actions=num_actions, memory=memory,\n",
        "                     nb_steps_warmup=1000, target_model_update=1, policy=policy)\n",
        "agent.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "logger = CSVLogger('dqn_cartpole.log')\n",
        "agent.fit(env, nb_steps=2000, visualize=False, verbose=2)\n",
        "agent.save_weights('dqn_cartpole.h5', overwrite=True)\n",
        "\n",
        "agent.load_weights('dqn_cartpole.h5')\n",
        "agent.test(env, nb_episodes=10, visualize=False)"
      ],
      "metadata": {
        "id": "mecc-5oflZlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines\n",
        "!pip install tensorflow==1.14"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MrRlmfm-sqFR",
        "outputId": "83215c21-0654-45fd-e187-c6191b603d34"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable_baselines\n",
            "  Downloading stable_baselines-2.10.2-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40 kB 40.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 81 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 122 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 163 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 194 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 204 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 235 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 27.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable_baselines) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable_baselines) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable_baselines) (1.3.5)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable_baselines) (0.17.3)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable_baselines) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable_baselines) (1.21.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable_baselines) (1.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable_baselines) (4.1.2.30)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable_baselines) (1.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable_baselines) (7.1.2)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable_baselines) (0.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.11->stable_baselines) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable_baselines) (0.16.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable_baselines) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->stable_baselines) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable_baselines) (2022.1)\n",
            "Installing collected packages: stable-baselines\n",
            "Successfully installed stable-baselines-2.10.2\n",
            "Collecting tensorflow==1.14\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 55 kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.0.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.44.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 40.4 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.21.6)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.5.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.8.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from stable_baselines.deepq.policies import MlpPolicy\n",
        "from stable_baselines import DQN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvdeHDpWsmRg",
        "outputId": "8eafe5ca-bbcd-47d9-87a0-65655882f0ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
            "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1')"
      ],
      "metadata": {
        "id": "Qn902WXesG1w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DQN(MlpPolicy, env, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUHvh8XisNqW",
        "outputId": "a1583d25-93bb-4ad8-ba19-ab58f0db8e05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/deepq/dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/deepq/build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/deepq/build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb683fd1f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb683fd1f50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb683fd1f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb683fd1f50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7abd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7abd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7abd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7abd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7afd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7afd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7afd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7afd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f7a150>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/deepq/build_graph.py:149: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67ed7c9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67ed7c9d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67ed7c9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67ed7c9d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f70e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f70e10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f70e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb683f70e10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5fd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5fd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee79f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee79f90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee79f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee79f90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecce550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecce550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecce550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecce550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee7b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee7b3d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee7b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee7b3d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee7b210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee7b210>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee7b210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ee7b210>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67ee7bdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67ee7bdd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67ee7bdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67ee7bdd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67edcad50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67edcad50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67edcad50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67edcad50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecb0f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecb0f50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecb0f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecb0f50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecb0f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecb0f50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecb0f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecb0f50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5cd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67eef5550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67eef5550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67eef5550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67eef5550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb67eef5550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe7d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe7d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe7d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe7d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ec3e110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ec3e110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ec3e110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ec3e110>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbeb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbeb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbeb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbeb90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe1d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe1d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe1d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb67ecbe1d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/deepq/build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/deepq/build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.learn(total_timesteps=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgSq7RoRsc78",
        "outputId": "7b997231-4ac3-44db-e6df-68105ea43bfe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------\n",
            "| % time spent exploring  | 2        |\n",
            "| episodes                | 100      |\n",
            "| mean 100 episode reward | 10.7     |\n",
            "| steps                   | 1058     |\n",
            "--------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines.deepq.dqn.DQN at 0x7fb683fd1cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('deepq_cartpole')"
      ],
      "metadata": {
        "id": "s9iii2-msw6k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs = env.reset()\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "    #env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "AaHOxweKtOfX",
        "outputId": "f64cfede-befe-42b0-9bf4-a226376191e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a7cb652d9bfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#env.render()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines/deepq/dqn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, mask, deterministic)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvectorized_env\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines/deepq/policies.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, obs, state, mask, deterministic)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1158\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mdirect\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \"\"\"\n\u001b[0;32m--> 473\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   5646\u001b[0m     context.context().context_switches.push(default.building_function,\n\u001b[1;32m   5647\u001b[0m                                             \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5648\u001b[0;31m                                             default._device_function_stack)\n\u001b[0m\u001b[1;32m   5649\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5650\u001b[0m       with super(_DefaultGraphStack,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, is_building_function, enter_context_fn, device_stack)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     self.stack.append(\n\u001b[0;32m--> 209\u001b[0;31m         ContextSwitch(is_building_function, enter_context_fn, device_stack))\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(_cls, is_building_function, enter_context_fn, device_stack)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "model = DQN(MlpPolicy, env, verbose=1)\n",
        "model.learn(total_timesteps=2000)\n",
        "model.save('deepq_cartpole')\n",
        "\n",
        "del model # remove to demonstrate saving and loading\n",
        "\n",
        "model = DQN.load('deepq_cartpole')\n",
        "\n",
        "obs = env.reset()\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "    env.render()"
      ],
      "metadata": {
        "id": "M0kTxnZtsk1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gym>=0.21.0\n",
        "!pip install -U gym[atari,accept-rom-license]"
      ],
      "metadata": {
        "id": "05IyV6aluZvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3"
      ],
      "metadata": {
        "id": "BIM4jAkdZwKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines.common.atari_wrappers import make_atari\n",
        "from stable_baselines.deepq.policies import MlpPolicy, CnnPolicy\n",
        "from stable_baselines import DQN"
      ],
      "metadata": {
        "id": "HwGM8eWquMWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = make_atari('BreakoutNoFrameskip-v4')\n",
        "\n",
        "model = DQN(CnnPolicy, env, verbose=1)\n",
        "model.learn(total_timesteps=25000)\n",
        "model.save('deepq_breakout')\n",
        "\n",
        "del model # remove to demonstrate saving and loading\n",
        "\n",
        "model = DQN.load('deepq_breakout')\n",
        "\n",
        "obs = env.reset()\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, dones, info = env.step(action)\n",
        "    env.render()"
      ],
      "metadata": {
        "id": "FMgA-4jZuKrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python dqn_cartpole.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LdZBZPzwqsW",
        "outputId": "b85f8675-832c-4e16-8c05-505fd702706f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "2022-05-12 14:55:12.009602: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2022-05-12 14:55:12.013036: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n",
            "2022-05-12 14:55:12.013245: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x21a5180 executing computations on platform Host. Devices:\n",
            "2022-05-12 14:55:12.013278: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2022-05-12 14:55:12.026340: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "0\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "300\n",
            "350\n",
            "400\n",
            "450\n",
            "500\n",
            "550\n",
            "600\n",
            "650\n",
            "700\n",
            "750\n",
            "800\n",
            "850\n",
            "900\n",
            "950\n",
            "1000\n",
            "1050\n",
            "1100\n",
            "1150\n",
            "1200\n",
            "1250\n",
            "1300\n",
            "1350\n",
            "1400\n",
            "1450\n",
            "1500\n",
            "1550\n",
            "1600\n",
            "1650\n",
            "1700\n",
            "1750\n"
          ]
        }
      ]
    }
  ]
}