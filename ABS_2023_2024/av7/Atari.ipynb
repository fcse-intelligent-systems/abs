{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "MTO96IfGt_Ju",
    "outputId": "d061d89b-85ca-4c7f-8231-3935c5db9772"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting gymnasium[atari]\n",
      "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m953.9/953.9 kB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (1.25.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (4.11.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium[atari])\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Collecting shimmy[atari]<1.0,>=0.1.0 (from gymnasium[atari])\n",
      "  Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0->gymnasium[atari])\n",
      "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m12.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[atari]) (6.4.0)\n",
      "Installing collected packages: farama-notifications, gymnasium, ale-py, shimmy\n",
      "Successfully installed ale-py-0.8.1 farama-notifications-0.0.4 gymnasium-0.29.1 shimmy-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium[atari]"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install gymnasium[accept-rom-license]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "jVjTUceCuNT1",
    "outputId": "b07740ae-1223-49c9-fce9-fd017c781f73"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: gymnasium[accept-rom-license] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (1.25.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (0.0.4)\n",
      "Collecting autorom[accept-rom-license]~=0.4.2 (from gymnasium[accept-rom-license])\n",
      "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (8.1.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (4.66.4)\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license])\n",
      "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m434.7/434.7 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2024.2.2)\n",
      "Building wheels for collected packages: AutoROM.accept-rom-license\n",
      "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446659 sha256=fef7dae5d4cdc5eec4d6aefba113a241e057e4bbc81b44ae6d8bca39a41e5d33\n",
      "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
      "Successfully built AutoROM.accept-rom-license\n",
      "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
      "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow import reduce_mean\n",
    "\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, state_space_shape, num_actions, model, target_model, learning_rate=0.1,\n",
    "                 discount_factor=0.95, batch_size=16, memory_size=100):\n",
    "        \"\"\"\n",
    "        Initializes Deep Q Network agent.\n",
    "        :param state_space_shape: shape of the observation space\n",
    "        :param num_actions: number of actions\n",
    "        :param model: Keras model\n",
    "        :param target_model: Keras model\n",
    "        :param learning_rate: learning rate\n",
    "        :param discount_factor: discount factor\n",
    "        :param batch_size: batch size\n",
    "        :param memory_size: maximum size of the experience replay memory\n",
    "        \"\"\"\n",
    "        self.state_space_shape = state_space_shape\n",
    "        self.num_actions = num_actions\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.model = model\n",
    "        self.target_model = target_model\n",
    "        self.update_target_model()\n",
    "\n",
    "    def update_memory(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        Adds experience tuple to experience replay memory.\n",
    "        :param state: current state\n",
    "        :param action: performed action\n",
    "        :param reward: reward received for performing action\n",
    "        :param next_state: next state\n",
    "        :param done: if episode has terminated after performing the action in the current state\n",
    "        \"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def update_target_model(self):\n",
    "        \"\"\"\n",
    "        Synchronize the target model with the main model.\n",
    "        \"\"\"\n",
    "        print('Updating target...')\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def get_action(self, state, epsilon):\n",
    "        \"\"\"\n",
    "        Returns the best action following epsilon greedy policy for the current state.\n",
    "        :param state: current state\n",
    "        :param epsilon: exploration rate\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        probability = np.random.random() + epsilon / self.num_actions\n",
    "        if probability < epsilon:\n",
    "            return np.random.randint(0, self.num_actions)\n",
    "        else:\n",
    "            if isinstance(self.state_space_shape, tuple):\n",
    "                state = state.reshape((1,) + self.state_space_shape)\n",
    "            else:\n",
    "                state = state.reshape(1, self.state_space_shape)\n",
    "            return np.argmax(self.model.predict(state, verbose=0)[0])\n",
    "\n",
    "    def load(self, model_name, episode):\n",
    "        \"\"\"\n",
    "        Loads the weights of the model at specified episode checkpoint.\n",
    "        :param model_name: name of the model\n",
    "        :param episode: episode checkpoint\n",
    "        \"\"\"\n",
    "        self.model.load_weights(f'dqn_{model_name}_{episode}.h5')\n",
    "\n",
    "    def save(self, model_name, episode):\n",
    "        \"\"\"\n",
    "        Stores the weights of the model at specified episode checkpoint.\n",
    "        :param model_name: name of the model\n",
    "        :param episode: episode checkpoint\n",
    "        \"\"\"\n",
    "        self.model.save_weights(f'dqn_{model_name}_{episode}.h5')\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Performs one step of model training.\n",
    "        \"\"\"\n",
    "        batch_size = min(self.batch_size, len(self.memory))\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        if isinstance(self.state_space_shape, tuple):\n",
    "            states = np.zeros((batch_size,) + self.state_space_shape)\n",
    "        else:\n",
    "            states = np.zeros((batch_size, self.state_space_shape))\n",
    "        actions = np.zeros((batch_size, self.num_actions))\n",
    "\n",
    "        for i in range(len(minibatch)):\n",
    "            state, action, reward, next_state, done = minibatch[i]\n",
    "            if done:\n",
    "                max_future_q = reward\n",
    "            else:\n",
    "                if isinstance(self.state_space_shape, tuple):\n",
    "                    next_state = next_state.reshape((1,) + self.state_space_shape)\n",
    "                else:\n",
    "                    next_state = next_state.reshape(1, self.state_space_shape)\n",
    "                max_future_q = (reward + self.discount_factor *\n",
    "                                np.amax(self.target_model.predict(next_state, verbose=0)[0]))\n",
    "            if isinstance(self.state_space_shape, tuple):\n",
    "                state = state.reshape((1,) + self.state_space_shape)\n",
    "            else:\n",
    "                state = state.reshape(1, self.state_space_shape)\n",
    "            target_q = self.model.predict(state, verbose=0)[0]\n",
    "            target_q[action] = max_future_q\n",
    "            states[i] = state\n",
    "            actions[i] = target_q\n",
    "\n",
    "        print('Training step...')\n",
    "        self.model.train_on_batch(states, actions)"
   ],
   "metadata": {
    "id": "KwdGfTwEvCC0"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "\n",
    "def build_model(state_space_shape, num_actions, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (2, 2), activation='relu', input_shape=state_space_shape))\n",
    "    model.add(Conv2D(16, (2, 2), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(num_actions, activation='linear'))\n",
    "    model.compile(Adam(lr=learning_rate), loss=MeanSquaredError())\n",
    "    return model"
   ],
   "metadata": {
    "id": "Wp8w_q59vZ6z"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def preprocess_state(state):\n",
    "    state_p = np.array(state, dtype=np.float64)\n",
    "    state_p /= 255\n",
    "    return state_p"
   ],
   "metadata": {
    "id": "K3-6K3R9vlE9"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_reward(reward):\n",
    "    return np.clip(reward, -1000., 1000.)"
   ],
   "metadata": {
    "id": "9VQ7yzq7voW_"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import gymnasium as gym"
   ],
   "metadata": {
    "id": "a2zKUusuv_Tf"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "env = gym.make('ALE/MsPacman-v5')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pkDJZoFYvtea",
    "outputId": "b71ae7da-249d-4efb-b9d0-06db439a9ab1"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "state_space_shape = env.observation_space.shape[:-1] + (3,)\n",
    "num_actions = env.action_space.n"
   ],
   "metadata": {
    "id": "_vqlYMyqvvpG"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_episodes = 10\n",
    "learning_rate = 0.01\n",
    "discount_factor = 1.0\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.995\n",
    "min_epsilon = 0.1\n",
    "batch_size = 8\n",
    "memory_size = 1000"
   ],
   "metadata": {
    "id": "cfjG1AwJvzJ2"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = build_model(state_space_shape, num_actions, learning_rate)\n",
    "target_model = build_model(state_space_shape, num_actions, learning_rate)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vqXXC210wEbZ",
    "outputId": "7cf82572-0a86-49e1-a34f-e9d309687c2b"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "agent = DQN(state_space_shape, num_actions, model, target_model, learning_rate,\n",
    "            discount_factor, batch_size, memory_size)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MaOjvZsTwH7W",
    "outputId": "a263d096-93b2-4ec9-bc31-3d570e82db47"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Updating target...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    state = preprocess_state(state)\n",
    "    done = False\n",
    "    rewards = 0\n",
    "    processed_rewards = 0\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        action = agent.get_action(state, epsilon)\n",
    "        new_state, reward, done, _, _ = env.step(action)\n",
    "        new_state = preprocess_state(new_state)\n",
    "        processed_reward = preprocess_reward(reward)\n",
    "        agent.update_memory(state, action, processed_reward, new_state, done)\n",
    "        state = new_state\n",
    "        rewards += reward\n",
    "        processed_rewards += processed_reward\n",
    "        steps += 1\n",
    "    agent.train()\n",
    "    print(f'Episode: {episode}, Original reward: {rewards}, Processed reward: {processed_rewards}, Steps: {steps}, Epsilon: {epsilon}')\n",
    "    if epsilon > min_epsilon:\n",
    "        epsilon *= epsilon_decay\n",
    "    if episode % 5 == 0:\n",
    "        agent.update_target_model()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EACFrnCBu-IP",
    "outputId": "342cc078-8c25-4ecd-a4b9-2c6cec7a5e0d"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training step...\n",
      "Episode: 0, Original reward: 380.0, Processed reward: 380.0, Steps: 701, Epsilon: 1.0\n",
      "Updating target...\n",
      "Training step...\n",
      "Episode: 1, Original reward: 300.0, Processed reward: 300.0, Steps: 395, Epsilon: 0.995\n",
      "Training step...\n",
      "Episode: 2, Original reward: 220.0, Processed reward: 220.0, Steps: 403, Epsilon: 0.990025\n",
      "Training step...\n",
      "Episode: 3, Original reward: 150.0, Processed reward: 150.0, Steps: 451, Epsilon: 0.985074875\n",
      "Training step...\n",
      "Episode: 4, Original reward: 660.0, Processed reward: 660.0, Steps: 825, Epsilon: 0.9801495006250001\n",
      "Training step...\n",
      "Episode: 5, Original reward: 170.0, Processed reward: 170.0, Steps: 401, Epsilon: 0.9752487531218751\n",
      "Updating target...\n",
      "Training step...\n",
      "Episode: 6, Original reward: 320.0, Processed reward: 320.0, Steps: 559, Epsilon: 0.9703725093562657\n",
      "Training step...\n",
      "Episode: 7, Original reward: 200.0, Processed reward: 200.0, Steps: 469, Epsilon: 0.9655206468094844\n",
      "Training step...\n",
      "Episode: 8, Original reward: 200.0, Processed reward: 200.0, Steps: 461, Epsilon: 0.960693043575437\n",
      "Training step...\n",
      "Episode: 9, Original reward: 1070.0, Processed reward: 1070.0, Steps: 723, Epsilon: 0.9558895783575597\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "done = False\n",
    "state, _ = env.reset()\n",
    "state = preprocess_state(state)\n",
    "# env.render()\n",
    "step = 0\n",
    "while not done:\n",
    "    action = agent.get_action(state, min_epsilon)\n",
    "    state, reward, done, _, _ = env.step(action)\n",
    "    state = preprocess_state(state)\n",
    "    reward = preprocess_reward(reward)\n",
    "    # env.render()\n",
    "    print(f'Step: {step}, Reward: {reward}')\n",
    "    step += 1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kit-iGoxB_4",
    "outputId": "eddf9484-6eb5-453e-f24a-f1858b5ce1d7"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Step: 0, Reward: 0.0\n",
      "Step: 1, Reward: 0.0\n",
      "Step: 2, Reward: 0.0\n",
      "Step: 3, Reward: 0.0\n",
      "Step: 4, Reward: 0.0\n",
      "Step: 5, Reward: 0.0\n",
      "Step: 6, Reward: 0.0\n",
      "Step: 7, Reward: 0.0\n",
      "Step: 8, Reward: 0.0\n",
      "Step: 9, Reward: 0.0\n",
      "Step: 10, Reward: 0.0\n",
      "Step: 11, Reward: 0.0\n",
      "Step: 12, Reward: 0.0\n",
      "Step: 13, Reward: 0.0\n",
      "Step: 14, Reward: 0.0\n",
      "Step: 15, Reward: 0.0\n",
      "Step: 16, Reward: 0.0\n",
      "Step: 17, Reward: 0.0\n",
      "Step: 18, Reward: 0.0\n",
      "Step: 19, Reward: 0.0\n",
      "Step: 20, Reward: 0.0\n",
      "Step: 21, Reward: 0.0\n",
      "Step: 22, Reward: 0.0\n",
      "Step: 23, Reward: 0.0\n",
      "Step: 24, Reward: 0.0\n",
      "Step: 25, Reward: 0.0\n",
      "Step: 26, Reward: 0.0\n",
      "Step: 27, Reward: 0.0\n",
      "Step: 28, Reward: 0.0\n",
      "Step: 29, Reward: 0.0\n",
      "Step: 30, Reward: 0.0\n",
      "Step: 31, Reward: 0.0\n",
      "Step: 32, Reward: 0.0\n",
      "Step: 33, Reward: 0.0\n",
      "Step: 34, Reward: 0.0\n",
      "Step: 35, Reward: 0.0\n",
      "Step: 36, Reward: 0.0\n",
      "Step: 37, Reward: 0.0\n",
      "Step: 38, Reward: 0.0\n",
      "Step: 39, Reward: 0.0\n",
      "Step: 40, Reward: 0.0\n",
      "Step: 41, Reward: 0.0\n",
      "Step: 42, Reward: 0.0\n",
      "Step: 43, Reward: 0.0\n",
      "Step: 44, Reward: 0.0\n",
      "Step: 45, Reward: 0.0\n",
      "Step: 46, Reward: 0.0\n",
      "Step: 47, Reward: 0.0\n",
      "Step: 48, Reward: 0.0\n",
      "Step: 49, Reward: 0.0\n",
      "Step: 50, Reward: 0.0\n",
      "Step: 51, Reward: 0.0\n",
      "Step: 52, Reward: 0.0\n",
      "Step: 53, Reward: 0.0\n",
      "Step: 54, Reward: 0.0\n",
      "Step: 55, Reward: 0.0\n",
      "Step: 56, Reward: 0.0\n",
      "Step: 57, Reward: 0.0\n",
      "Step: 58, Reward: 0.0\n",
      "Step: 59, Reward: 0.0\n",
      "Step: 60, Reward: 0.0\n",
      "Step: 61, Reward: 0.0\n",
      "Step: 62, Reward: 0.0\n",
      "Step: 63, Reward: 0.0\n",
      "Step: 64, Reward: 0.0\n",
      "Step: 65, Reward: 0.0\n",
      "Step: 66, Reward: 0.0\n",
      "Step: 67, Reward: 10.0\n",
      "Step: 68, Reward: 0.0\n",
      "Step: 69, Reward: 0.0\n",
      "Step: 70, Reward: 10.0\n",
      "Step: 71, Reward: 0.0\n",
      "Step: 72, Reward: 0.0\n",
      "Step: 73, Reward: 10.0\n",
      "Step: 74, Reward: 0.0\n",
      "Step: 75, Reward: 0.0\n",
      "Step: 76, Reward: 0.0\n",
      "Step: 77, Reward: 10.0\n",
      "Step: 78, Reward: 0.0\n",
      "Step: 79, Reward: 0.0\n",
      "Step: 80, Reward: 10.0\n",
      "Step: 81, Reward: 0.0\n",
      "Step: 82, Reward: 0.0\n",
      "Step: 83, Reward: 0.0\n",
      "Step: 84, Reward: 10.0\n",
      "Step: 85, Reward: 0.0\n",
      "Step: 86, Reward: 0.0\n",
      "Step: 87, Reward: 10.0\n",
      "Step: 88, Reward: 0.0\n",
      "Step: 89, Reward: 0.0\n",
      "Step: 90, Reward: 0.0\n",
      "Step: 91, Reward: 0.0\n",
      "Step: 92, Reward: 0.0\n",
      "Step: 93, Reward: 0.0\n",
      "Step: 94, Reward: 0.0\n",
      "Step: 95, Reward: 0.0\n",
      "Step: 96, Reward: 0.0\n",
      "Step: 97, Reward: 0.0\n",
      "Step: 98, Reward: 0.0\n",
      "Step: 99, Reward: 0.0\n",
      "Step: 100, Reward: 0.0\n",
      "Step: 101, Reward: 0.0\n",
      "Step: 102, Reward: 0.0\n",
      "Step: 103, Reward: 0.0\n",
      "Step: 104, Reward: 0.0\n",
      "Step: 105, Reward: 0.0\n",
      "Step: 106, Reward: 0.0\n",
      "Step: 107, Reward: 0.0\n",
      "Step: 108, Reward: 0.0\n",
      "Step: 109, Reward: 0.0\n",
      "Step: 110, Reward: 0.0\n",
      "Step: 111, Reward: 0.0\n",
      "Step: 112, Reward: 0.0\n",
      "Step: 113, Reward: 0.0\n",
      "Step: 114, Reward: 0.0\n",
      "Step: 115, Reward: 0.0\n",
      "Step: 116, Reward: 0.0\n",
      "Step: 117, Reward: 0.0\n",
      "Step: 118, Reward: 0.0\n",
      "Step: 119, Reward: 0.0\n",
      "Step: 120, Reward: 0.0\n",
      "Step: 121, Reward: 0.0\n",
      "Step: 122, Reward: 0.0\n",
      "Step: 123, Reward: 0.0\n",
      "Step: 124, Reward: 0.0\n",
      "Step: 125, Reward: 0.0\n",
      "Step: 126, Reward: 0.0\n",
      "Step: 127, Reward: 0.0\n",
      "Step: 128, Reward: 0.0\n",
      "Step: 129, Reward: 0.0\n",
      "Step: 130, Reward: 0.0\n",
      "Step: 131, Reward: 0.0\n",
      "Step: 132, Reward: 0.0\n",
      "Step: 133, Reward: 0.0\n",
      "Step: 134, Reward: 0.0\n",
      "Step: 135, Reward: 0.0\n",
      "Step: 136, Reward: 0.0\n",
      "Step: 137, Reward: 0.0\n",
      "Step: 138, Reward: 0.0\n",
      "Step: 139, Reward: 0.0\n",
      "Step: 140, Reward: 0.0\n",
      "Step: 141, Reward: 10.0\n",
      "Step: 142, Reward: 0.0\n",
      "Step: 143, Reward: 0.0\n",
      "Step: 144, Reward: 0.0\n",
      "Step: 145, Reward: 10.0\n",
      "Step: 146, Reward: 0.0\n",
      "Step: 147, Reward: 0.0\n",
      "Step: 148, Reward: 10.0\n",
      "Step: 149, Reward: 0.0\n",
      "Step: 150, Reward: 0.0\n",
      "Step: 151, Reward: 0.0\n",
      "Step: 152, Reward: 0.0\n",
      "Step: 153, Reward: 0.0\n",
      "Step: 154, Reward: 0.0\n",
      "Step: 155, Reward: 0.0\n",
      "Step: 156, Reward: 0.0\n",
      "Step: 157, Reward: 0.0\n",
      "Step: 158, Reward: 0.0\n",
      "Step: 159, Reward: 0.0\n",
      "Step: 160, Reward: 0.0\n",
      "Step: 161, Reward: 0.0\n",
      "Step: 162, Reward: 0.0\n",
      "Step: 163, Reward: 0.0\n",
      "Step: 164, Reward: 0.0\n",
      "Step: 165, Reward: 0.0\n",
      "Step: 166, Reward: 0.0\n",
      "Step: 167, Reward: 0.0\n",
      "Step: 168, Reward: 0.0\n",
      "Step: 169, Reward: 0.0\n",
      "Step: 170, Reward: 0.0\n",
      "Step: 171, Reward: 0.0\n",
      "Step: 172, Reward: 0.0\n",
      "Step: 173, Reward: 0.0\n",
      "Step: 174, Reward: 0.0\n",
      "Step: 175, Reward: 0.0\n",
      "Step: 176, Reward: 0.0\n",
      "Step: 177, Reward: 0.0\n",
      "Step: 178, Reward: 0.0\n",
      "Step: 179, Reward: 0.0\n",
      "Step: 180, Reward: 0.0\n",
      "Step: 181, Reward: 0.0\n",
      "Step: 182, Reward: 0.0\n",
      "Step: 183, Reward: 0.0\n",
      "Step: 184, Reward: 0.0\n",
      "Step: 185, Reward: 0.0\n",
      "Step: 186, Reward: 0.0\n",
      "Step: 187, Reward: 0.0\n",
      "Step: 188, Reward: 0.0\n",
      "Step: 189, Reward: 0.0\n",
      "Step: 190, Reward: 0.0\n",
      "Step: 191, Reward: 0.0\n",
      "Step: 192, Reward: 0.0\n",
      "Step: 193, Reward: 0.0\n",
      "Step: 194, Reward: 0.0\n",
      "Step: 195, Reward: 0.0\n",
      "Step: 196, Reward: 0.0\n",
      "Step: 197, Reward: 0.0\n",
      "Step: 198, Reward: 0.0\n",
      "Step: 199, Reward: 0.0\n",
      "Step: 200, Reward: 0.0\n",
      "Step: 201, Reward: 0.0\n",
      "Step: 202, Reward: 0.0\n",
      "Step: 203, Reward: 0.0\n",
      "Step: 204, Reward: 0.0\n",
      "Step: 205, Reward: 0.0\n",
      "Step: 206, Reward: 0.0\n",
      "Step: 207, Reward: 0.0\n",
      "Step: 208, Reward: 0.0\n",
      "Step: 209, Reward: 0.0\n",
      "Step: 210, Reward: 0.0\n",
      "Step: 211, Reward: 0.0\n",
      "Step: 212, Reward: 0.0\n",
      "Step: 213, Reward: 0.0\n",
      "Step: 214, Reward: 0.0\n",
      "Step: 215, Reward: 0.0\n",
      "Step: 216, Reward: 0.0\n",
      "Step: 217, Reward: 0.0\n",
      "Step: 218, Reward: 0.0\n",
      "Step: 219, Reward: 0.0\n",
      "Step: 220, Reward: 0.0\n",
      "Step: 221, Reward: 0.0\n",
      "Step: 222, Reward: 0.0\n",
      "Step: 223, Reward: 0.0\n",
      "Step: 224, Reward: 0.0\n",
      "Step: 225, Reward: 0.0\n",
      "Step: 226, Reward: 0.0\n",
      "Step: 227, Reward: 0.0\n",
      "Step: 228, Reward: 0.0\n",
      "Step: 229, Reward: 0.0\n",
      "Step: 230, Reward: 0.0\n",
      "Step: 231, Reward: 0.0\n",
      "Step: 232, Reward: 0.0\n",
      "Step: 233, Reward: 0.0\n",
      "Step: 234, Reward: 0.0\n",
      "Step: 235, Reward: 0.0\n",
      "Step: 236, Reward: 0.0\n",
      "Step: 237, Reward: 0.0\n",
      "Step: 238, Reward: 0.0\n",
      "Step: 239, Reward: 0.0\n",
      "Step: 240, Reward: 0.0\n",
      "Step: 241, Reward: 0.0\n",
      "Step: 242, Reward: 0.0\n",
      "Step: 243, Reward: 0.0\n",
      "Step: 244, Reward: 0.0\n",
      "Step: 245, Reward: 0.0\n",
      "Step: 246, Reward: 0.0\n",
      "Step: 247, Reward: 0.0\n",
      "Step: 248, Reward: 0.0\n",
      "Step: 249, Reward: 0.0\n",
      "Step: 250, Reward: 0.0\n",
      "Step: 251, Reward: 0.0\n",
      "Step: 252, Reward: 0.0\n",
      "Step: 253, Reward: 0.0\n",
      "Step: 254, Reward: 0.0\n",
      "Step: 255, Reward: 0.0\n",
      "Step: 256, Reward: 0.0\n",
      "Step: 257, Reward: 0.0\n",
      "Step: 258, Reward: 10.0\n",
      "Step: 259, Reward: 0.0\n",
      "Step: 260, Reward: 0.0\n",
      "Step: 261, Reward: 0.0\n",
      "Step: 262, Reward: 0.0\n",
      "Step: 263, Reward: 0.0\n",
      "Step: 264, Reward: 0.0\n",
      "Step: 265, Reward: 10.0\n",
      "Step: 266, Reward: 0.0\n",
      "Step: 267, Reward: 0.0\n",
      "Step: 268, Reward: 10.0\n",
      "Step: 269, Reward: 0.0\n",
      "Step: 270, Reward: 0.0\n",
      "Step: 271, Reward: 10.0\n",
      "Step: 272, Reward: 0.0\n",
      "Step: 273, Reward: 0.0\n",
      "Step: 274, Reward: 0.0\n",
      "Step: 275, Reward: 10.0\n",
      "Step: 276, Reward: 0.0\n",
      "Step: 277, Reward: 0.0\n",
      "Step: 278, Reward: 0.0\n",
      "Step: 279, Reward: 10.0\n",
      "Step: 280, Reward: 0.0\n",
      "Step: 281, Reward: 0.0\n",
      "Step: 282, Reward: 10.0\n",
      "Step: 283, Reward: 0.0\n",
      "Step: 284, Reward: 0.0\n",
      "Step: 285, Reward: 10.0\n",
      "Step: 286, Reward: 0.0\n",
      "Step: 287, Reward: 0.0\n",
      "Step: 288, Reward: 50.0\n",
      "Step: 289, Reward: 0.0\n",
      "Step: 290, Reward: 0.0\n",
      "Step: 291, Reward: 10.0\n",
      "Step: 292, Reward: 0.0\n",
      "Step: 293, Reward: 0.0\n",
      "Step: 294, Reward: 0.0\n",
      "Step: 295, Reward: 0.0\n",
      "Step: 296, Reward: 0.0\n",
      "Step: 297, Reward: 0.0\n",
      "Step: 298, Reward: 0.0\n",
      "Step: 299, Reward: 0.0\n",
      "Step: 300, Reward: 0.0\n",
      "Step: 301, Reward: 0.0\n",
      "Step: 302, Reward: 0.0\n",
      "Step: 303, Reward: 0.0\n",
      "Step: 304, Reward: 0.0\n",
      "Step: 305, Reward: 0.0\n",
      "Step: 306, Reward: 0.0\n",
      "Step: 307, Reward: 0.0\n",
      "Step: 308, Reward: 0.0\n",
      "Step: 309, Reward: 0.0\n",
      "Step: 310, Reward: 0.0\n",
      "Step: 311, Reward: 0.0\n",
      "Step: 312, Reward: 0.0\n",
      "Step: 313, Reward: 0.0\n",
      "Step: 314, Reward: 0.0\n",
      "Step: 315, Reward: 0.0\n",
      "Step: 316, Reward: 0.0\n",
      "Step: 317, Reward: 0.0\n",
      "Step: 318, Reward: 0.0\n",
      "Step: 319, Reward: 0.0\n",
      "Step: 320, Reward: 0.0\n",
      "Step: 321, Reward: 0.0\n",
      "Step: 322, Reward: 0.0\n",
      "Step: 323, Reward: 0.0\n",
      "Step: 324, Reward: 0.0\n",
      "Step: 325, Reward: 0.0\n",
      "Step: 326, Reward: 0.0\n",
      "Step: 327, Reward: 0.0\n",
      "Step: 328, Reward: 0.0\n",
      "Step: 329, Reward: 0.0\n",
      "Step: 330, Reward: 0.0\n",
      "Step: 331, Reward: 0.0\n",
      "Step: 332, Reward: 0.0\n",
      "Step: 333, Reward: 0.0\n",
      "Step: 334, Reward: 0.0\n",
      "Step: 335, Reward: 0.0\n",
      "Step: 336, Reward: 0.0\n",
      "Step: 337, Reward: 0.0\n",
      "Step: 338, Reward: 0.0\n",
      "Step: 339, Reward: 0.0\n",
      "Step: 340, Reward: 0.0\n",
      "Step: 341, Reward: 0.0\n",
      "Step: 342, Reward: 0.0\n",
      "Step: 343, Reward: 0.0\n",
      "Step: 344, Reward: 0.0\n",
      "Step: 345, Reward: 0.0\n",
      "Step: 346, Reward: 0.0\n",
      "Step: 347, Reward: 0.0\n",
      "Step: 348, Reward: 0.0\n",
      "Step: 349, Reward: 0.0\n",
      "Step: 350, Reward: 0.0\n",
      "Step: 351, Reward: 0.0\n",
      "Step: 352, Reward: 0.0\n",
      "Step: 353, Reward: 0.0\n",
      "Step: 354, Reward: 0.0\n",
      "Step: 355, Reward: 0.0\n",
      "Step: 356, Reward: 0.0\n",
      "Step: 357, Reward: 0.0\n",
      "Step: 358, Reward: 0.0\n",
      "Step: 359, Reward: 0.0\n",
      "Step: 360, Reward: 0.0\n",
      "Step: 361, Reward: 0.0\n",
      "Step: 362, Reward: 0.0\n",
      "Step: 363, Reward: 0.0\n",
      "Step: 364, Reward: 0.0\n",
      "Step: 365, Reward: 0.0\n",
      "Step: 366, Reward: 0.0\n",
      "Step: 367, Reward: 0.0\n",
      "Step: 368, Reward: 0.0\n",
      "Step: 369, Reward: 0.0\n",
      "Step: 370, Reward: 0.0\n",
      "Step: 371, Reward: 0.0\n",
      "Step: 372, Reward: 0.0\n",
      "Step: 373, Reward: 0.0\n",
      "Step: 374, Reward: 0.0\n",
      "Step: 375, Reward: 0.0\n",
      "Step: 376, Reward: 0.0\n",
      "Step: 377, Reward: 0.0\n",
      "Step: 378, Reward: 0.0\n",
      "Step: 379, Reward: 0.0\n",
      "Step: 380, Reward: 0.0\n",
      "Step: 381, Reward: 0.0\n",
      "Step: 382, Reward: 0.0\n",
      "Step: 383, Reward: 0.0\n",
      "Step: 384, Reward: 0.0\n",
      "Step: 385, Reward: 0.0\n",
      "Step: 386, Reward: 0.0\n",
      "Step: 387, Reward: 0.0\n",
      "Step: 388, Reward: 0.0\n",
      "Step: 389, Reward: 0.0\n",
      "Step: 390, Reward: 0.0\n",
      "Step: 391, Reward: 0.0\n",
      "Step: 392, Reward: 0.0\n",
      "Step: 393, Reward: 0.0\n",
      "Step: 394, Reward: 0.0\n",
      "Step: 395, Reward: 0.0\n",
      "Step: 396, Reward: 0.0\n",
      "Step: 397, Reward: 0.0\n",
      "Step: 398, Reward: 0.0\n",
      "Step: 399, Reward: 0.0\n",
      "Step: 400, Reward: 0.0\n",
      "Step: 401, Reward: 0.0\n",
      "Step: 402, Reward: 0.0\n",
      "Step: 403, Reward: 0.0\n",
      "Step: 404, Reward: 0.0\n",
      "Step: 405, Reward: 0.0\n",
      "Step: 406, Reward: 200.0\n",
      "Step: 407, Reward: 0.0\n",
      "Step: 408, Reward: 0.0\n",
      "Step: 409, Reward: 0.0\n",
      "Step: 410, Reward: 0.0\n",
      "Step: 411, Reward: 0.0\n",
      "Step: 412, Reward: 0.0\n",
      "Step: 413, Reward: 0.0\n",
      "Step: 414, Reward: 0.0\n",
      "Step: 415, Reward: 0.0\n",
      "Step: 416, Reward: 0.0\n",
      "Step: 417, Reward: 0.0\n",
      "Step: 418, Reward: 0.0\n",
      "Step: 419, Reward: 0.0\n",
      "Step: 420, Reward: 0.0\n",
      "Step: 421, Reward: 0.0\n",
      "Step: 422, Reward: 0.0\n",
      "Step: 423, Reward: 0.0\n",
      "Step: 424, Reward: 0.0\n",
      "Step: 425, Reward: 0.0\n",
      "Step: 426, Reward: 0.0\n",
      "Step: 427, Reward: 0.0\n",
      "Step: 428, Reward: 0.0\n",
      "Step: 429, Reward: 0.0\n",
      "Step: 430, Reward: 0.0\n",
      "Step: 431, Reward: 0.0\n",
      "Step: 432, Reward: 0.0\n",
      "Step: 433, Reward: 0.0\n",
      "Step: 434, Reward: 0.0\n",
      "Step: 435, Reward: 0.0\n",
      "Step: 436, Reward: 0.0\n",
      "Step: 437, Reward: 0.0\n",
      "Step: 438, Reward: 0.0\n",
      "Step: 439, Reward: 0.0\n",
      "Step: 440, Reward: 0.0\n",
      "Step: 441, Reward: 0.0\n",
      "Step: 442, Reward: 0.0\n",
      "Step: 443, Reward: 0.0\n",
      "Step: 444, Reward: 0.0\n",
      "Step: 445, Reward: 0.0\n",
      "Step: 446, Reward: 0.0\n",
      "Step: 447, Reward: 0.0\n",
      "Step: 448, Reward: 0.0\n",
      "Step: 449, Reward: 0.0\n",
      "Step: 450, Reward: 0.0\n",
      "Step: 451, Reward: 0.0\n",
      "Step: 452, Reward: 0.0\n",
      "Step: 453, Reward: 0.0\n",
      "Step: 454, Reward: 0.0\n",
      "Step: 455, Reward: 0.0\n",
      "Step: 456, Reward: 0.0\n",
      "Step: 457, Reward: 0.0\n",
      "Step: 458, Reward: 0.0\n",
      "Step: 459, Reward: 0.0\n",
      "Step: 460, Reward: 0.0\n",
      "Step: 461, Reward: 0.0\n",
      "Step: 462, Reward: 0.0\n",
      "Step: 463, Reward: 0.0\n",
      "Step: 464, Reward: 0.0\n",
      "Step: 465, Reward: 0.0\n",
      "Step: 466, Reward: 0.0\n",
      "Step: 467, Reward: 0.0\n",
      "Step: 468, Reward: 0.0\n",
      "Step: 469, Reward: 0.0\n",
      "Step: 470, Reward: 0.0\n",
      "Step: 471, Reward: 0.0\n",
      "Step: 472, Reward: 0.0\n",
      "Step: 473, Reward: 0.0\n",
      "Step: 474, Reward: 0.0\n",
      "Step: 475, Reward: 0.0\n",
      "Step: 476, Reward: 0.0\n",
      "Step: 477, Reward: 0.0\n",
      "Step: 478, Reward: 0.0\n",
      "Step: 479, Reward: 0.0\n",
      "Step: 480, Reward: 0.0\n",
      "Step: 481, Reward: 0.0\n",
      "Step: 482, Reward: 0.0\n",
      "Step: 483, Reward: 0.0\n",
      "Step: 484, Reward: 0.0\n",
      "Step: 485, Reward: 0.0\n",
      "Step: 486, Reward: 0.0\n",
      "Step: 487, Reward: 0.0\n",
      "Step: 488, Reward: 0.0\n",
      "Step: 489, Reward: 0.0\n",
      "Step: 490, Reward: 0.0\n",
      "Step: 491, Reward: 0.0\n",
      "Step: 492, Reward: 0.0\n",
      "Step: 493, Reward: 0.0\n",
      "Step: 494, Reward: 0.0\n",
      "Step: 495, Reward: 0.0\n",
      "Step: 496, Reward: 0.0\n",
      "Step: 497, Reward: 0.0\n",
      "Step: 498, Reward: 0.0\n",
      "Step: 499, Reward: 0.0\n",
      "Step: 500, Reward: 0.0\n",
      "Step: 501, Reward: 0.0\n",
      "Step: 502, Reward: 0.0\n",
      "Step: 503, Reward: 0.0\n",
      "Step: 504, Reward: 0.0\n",
      "Step: 505, Reward: 0.0\n",
      "Step: 506, Reward: 0.0\n",
      "Step: 507, Reward: 0.0\n",
      "Step: 508, Reward: 0.0\n",
      "Step: 509, Reward: 0.0\n",
      "Step: 510, Reward: 0.0\n",
      "Step: 511, Reward: 0.0\n",
      "Step: 512, Reward: 0.0\n",
      "Step: 513, Reward: 0.0\n",
      "Step: 514, Reward: 0.0\n",
      "Step: 515, Reward: 0.0\n",
      "Step: 516, Reward: 0.0\n",
      "Step: 517, Reward: 0.0\n",
      "Step: 518, Reward: 0.0\n",
      "Step: 519, Reward: 0.0\n",
      "Step: 520, Reward: 0.0\n",
      "Step: 521, Reward: 0.0\n",
      "Step: 522, Reward: 0.0\n",
      "Step: 523, Reward: 0.0\n",
      "Step: 524, Reward: 0.0\n",
      "Step: 525, Reward: 0.0\n",
      "Step: 526, Reward: 0.0\n",
      "Step: 527, Reward: 0.0\n",
      "Step: 528, Reward: 0.0\n",
      "Step: 529, Reward: 0.0\n",
      "Step: 530, Reward: 10.0\n",
      "Step: 531, Reward: 0.0\n",
      "Step: 532, Reward: 0.0\n",
      "Step: 533, Reward: 10.0\n",
      "Step: 534, Reward: 0.0\n",
      "Step: 535, Reward: 0.0\n",
      "Step: 536, Reward: 0.0\n",
      "Step: 537, Reward: 10.0\n",
      "Step: 538, Reward: 0.0\n",
      "Step: 539, Reward: 0.0\n",
      "Step: 540, Reward: 0.0\n",
      "Step: 541, Reward: 10.0\n",
      "Step: 542, Reward: 0.0\n",
      "Step: 543, Reward: 0.0\n",
      "Step: 544, Reward: 10.0\n",
      "Step: 545, Reward: 0.0\n",
      "Step: 546, Reward: 0.0\n",
      "Step: 547, Reward: 0.0\n",
      "Step: 548, Reward: 0.0\n",
      "Step: 549, Reward: 0.0\n",
      "Step: 550, Reward: 0.0\n",
      "Step: 551, Reward: 0.0\n",
      "Step: 552, Reward: 0.0\n",
      "Step: 553, Reward: 0.0\n",
      "Step: 554, Reward: 0.0\n",
      "Step: 555, Reward: 0.0\n",
      "Step: 556, Reward: 0.0\n",
      "Step: 557, Reward: 0.0\n",
      "Step: 558, Reward: 0.0\n",
      "Step: 559, Reward: 0.0\n",
      "Step: 560, Reward: 0.0\n",
      "Step: 561, Reward: 0.0\n",
      "Step: 562, Reward: 0.0\n",
      "Step: 563, Reward: 0.0\n",
      "Step: 564, Reward: 0.0\n",
      "Step: 565, Reward: 0.0\n",
      "Step: 566, Reward: 0.0\n",
      "Step: 567, Reward: 0.0\n",
      "Step: 568, Reward: 0.0\n",
      "Step: 569, Reward: 0.0\n",
      "Step: 570, Reward: 0.0\n",
      "Step: 571, Reward: 0.0\n",
      "Step: 572, Reward: 0.0\n",
      "Step: 573, Reward: 0.0\n",
      "Step: 574, Reward: 0.0\n",
      "Step: 575, Reward: 0.0\n",
      "Step: 576, Reward: 0.0\n",
      "Step: 577, Reward: 0.0\n",
      "Step: 578, Reward: 0.0\n",
      "Step: 579, Reward: 0.0\n",
      "Step: 580, Reward: 0.0\n",
      "Step: 581, Reward: 0.0\n",
      "Step: 582, Reward: 0.0\n",
      "Step: 583, Reward: 0.0\n",
      "Step: 584, Reward: 0.0\n",
      "Step: 585, Reward: 0.0\n",
      "Step: 586, Reward: 0.0\n",
      "Step: 587, Reward: 0.0\n",
      "Step: 588, Reward: 0.0\n",
      "Step: 589, Reward: 0.0\n",
      "Step: 590, Reward: 0.0\n",
      "Step: 591, Reward: 0.0\n",
      "Step: 592, Reward: 0.0\n",
      "Step: 593, Reward: 0.0\n",
      "Step: 594, Reward: 0.0\n",
      "Step: 595, Reward: 0.0\n",
      "Step: 596, Reward: 0.0\n",
      "Step: 597, Reward: 0.0\n",
      "Step: 598, Reward: 0.0\n",
      "Step: 599, Reward: 0.0\n",
      "Step: 600, Reward: 0.0\n",
      "Step: 601, Reward: 0.0\n",
      "Step: 602, Reward: 0.0\n",
      "Step: 603, Reward: 0.0\n",
      "Step: 604, Reward: 0.0\n",
      "Step: 605, Reward: 0.0\n",
      "Step: 606, Reward: 0.0\n",
      "Step: 607, Reward: 0.0\n",
      "Step: 608, Reward: 0.0\n"
     ]
    }
   ]
  }
 ]
}
